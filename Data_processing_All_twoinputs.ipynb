{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import spectrum\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "use_freq_resp = True\n",
    "remove_dc = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'D://Xin Zhang/Sensor/conbination/NewData/All'\n",
    "file_list = [y for x in os.walk(dir_name) for y in glob(os.path.join(x[0], '*.txt'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "for j in file_list:\n",
    "    temp_df = pd.read_csv(j, sep = \"\\t\")\n",
    "    \n",
    "    for x in temp_df.columns:\n",
    "        temp_df[x] = pd.to_numeric(temp_df[x], downcast=\"float\")   \n",
    "\n",
    "    all_data.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(debug):\n",
    "    ctr = 0 \n",
    "    for j in range(len(all_data)):\n",
    "        if('Multi' in file_list[j]):\n",
    "            if('trough' in file_list[j]):\n",
    "                peak_index,_ = find_peaks(-all_data[j]['Current (A)'],distance=3500)\n",
    "                peaks = peak_index/1000\n",
    "            elif('peak' in file_list[j]):\n",
    "                peak_index,_ = find_peaks(all_data[j]['Current (A)'],distance=3500)\n",
    "                peaks = peak_index/1000\n",
    "                \n",
    "            plt.plot(all_data[j]['Elapsed Time (s)'], all_data[j]['Current (A)'])\n",
    "            plt.scatter(peaks, all_data[j]['Current (A)'][peak_index], c='red')\n",
    "        \n",
    "            plt.title(file_list[ctr].rsplit('/', 1)[1].rsplit('\\\\',2)[2])\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Current (A)\")\n",
    "            plt.pause(0.0001)\n",
    "            ctr += 1\n",
    "        else:\n",
    "            plt.plot(all_data[j]['Elapsed Time (s)'], all_data[j]['Current (A)'])       \n",
    "            plt.title(file_list[ctr].rsplit('/', 1)[1].rsplit('\\\\',2)[2])\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Current (A)\")\n",
    "            plt.pause(0.0001)\n",
    "            ctr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of multi-files is  79\n",
      "Too close to the end in All\\MOVE-NODING\\MOVE-NODING - Copy (31).txt\n",
      "fixed (end) length is 3000\n",
      "================================================\n",
      "Too close to the end in All\\MOVE-SHAKING\\MOVE-SHAKING - Copy (48).txt\n",
      "fixed (end) length is 3000\n",
      "================================================\n",
      "Too close to the end in All\\Nodding_No_Multi_trough\\Nodding_No_6 in 1_5s per file - Copy (10).txt\n",
      "fixed (end) length is 3000\n",
      "================================================\n",
      "Too close to the end in All\\Nodding_Yes\\SPEAK-YES-NODING - 10.txt\n",
      "fixed (end) length is 3000\n",
      "================================================\n",
      "Too close to the end in All\\Nodding_Yes\\SPEAK-YES-NODING - 11.txt\n",
      "fixed (end) length is 3000\n",
      "================================================\n",
      "Too close to the end in All\\Nodding_Yes\\SPEAK-YES-NODING - 146.txt\n",
      "fixed (end) length is 3000\n",
      "================================================\n",
      "Too close to the start in All\\Shaking_Yes_Multi_trough\\Shaking_Yes-No_5 in 1_5s per file - Copy (14).txt\n",
      "fixed (start) length is 3000\n",
      "================================================\n",
      "Too close to the start in All\\Shaking_Yes_Multi_trough\\Shaking_Yes-No_5 in 1_5s per file - Copy (15).txt\n",
      "fixed (start) length is 3000\n",
      "================================================\n",
      "Too close to the start in All\\Shaking_Yes_Multi_trough\\Shaking_Yes-No_6 in 1_5s per file - Copy (17).txt\n",
      "fixed (start) length is 3000\n",
      "================================================\n",
      "Too close to the end in All\\SPEAK-ONE\\SPEAK-ONE - Copy (26).txt\n",
      "fixed (end) length is 3000\n",
      "================================================\n",
      "Too close to the end in All\\SPEAK-YES\\SPEAK-YES - Copy (22).txt\n",
      "fixed (end) length is 3000\n",
      "================================================\n",
      "Too close to the start in All\\stretch_Multi_trough\\stretch_No_14 in 1_5s per file - Copy - Copy (3).txt\n",
      "fixed (start) length is 3000\n",
      "================================================\n",
      "Too close to the start in All\\stretch_Multi_trough\\stretch_No_24 in 1_5s per file - Copy - Copy (2).txt\n",
      "fixed (start) length is 3000\n",
      "================================================\n",
      "Too close to the start in All\\stretch_Multi_trough\\stretch_No_26 in 1_5s per file - Copy - Copy.txt\n",
      "fixed (start) length is 3000\n",
      "================================================\n",
      "Too close to the start in All\\stretch_Multi_trough\\stretch_No_48 in 1_5s per file - Copy.txt\n",
      "fixed (start) length is 3000\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "num_files = len(all_data)\n",
    "sampling_rate = 1000 # In Hz\n",
    "length_keep = 3500\n",
    "num_samples_to_keep_before = 1500\n",
    "num_samples_to_keep_after = 1500\n",
    "total_num_samples_to_keep = 3000\n",
    "\n",
    "num_multi_files = 0\n",
    "for i in range(num_files):\n",
    "    if('Multi' in file_list[i]):\n",
    "        num_multi_files+=1\n",
    "print('The number of multi-files is ', num_multi_files)\n",
    "extra_signal_number = (4-1)*2+(5-1)*10+(6-1)*62+(14-1)+(24-1)+(26-1)+(30-1)+(48-1)\n",
    "\n",
    "new_file_list = [ [] for _ in range(num_files + extra_signal_number)]\n",
    "reserved_samples = [ [] for _ in range(num_files + extra_signal_number)]\n",
    "reserved_time = [ [] for _ in range(num_files + extra_signal_number)]\n",
    "time_to_keep = np.linspace(0,total_num_samples_to_keep, num = total_num_samples_to_keep)\n",
    "\n",
    "\n",
    "class_all = [ [] for _ in range(num_files + extra_signal_number)]\n",
    "\n",
    "class1 = ['YES','Yes','yes']\n",
    "class2 = ['NO','No','no']\n",
    "class3 = ['ONE','One','one']\n",
    "class4 = ['Two','TWO','two']\n",
    "\n",
    "class5 = ['SHAKING','Shaking','shaking']\n",
    "class6 = ['NODING','Noding','noding']\n",
    "class7 = ['STRETCH','Stretch','stretch']\n",
    "\n",
    "class8 = ['Nodding_No']\n",
    "class9 = ['Nodding_Yes']\n",
    "class10 = ['Shaking_No']\n",
    "class11 = ['Shaking_Yes']\n",
    "# class12 = ['Shaking_One']\n",
    "\n",
    "x=0\n",
    "for i in range(num_files):\n",
    "    class_match = False\n",
    "    \n",
    "    temp_data = all_data[i]\n",
    "    actual_name = file_list[i].rsplit('/', 1)[1].rsplit('.',1)[0].rsplit('\\\\',2)[1]\n",
    "    \n",
    "    # deal with Multi =================================================================================\n",
    "    if('Multi' in file_list[i]):\n",
    "        if('trough' in file_list[i]):\n",
    "            peak_index,_ = find_peaks(-temp_data['Current (A)'],distance=3500)\n",
    "            if('No_4' in file_list[i]):\n",
    "                temp_six_peak = temp_data['Current (A)'][peak_index].nsmallest(4).index\n",
    "            if('No_5' in file_list[i]):\n",
    "                temp_six_peak = temp_data['Current (A)'][peak_index].nsmallest(5).index\n",
    "            if('No_6' in file_list[i]):\n",
    "                temp_six_peak = temp_data['Current (A)'][peak_index].nsmallest(6).index\n",
    "            if('No_14' in file_list[i]):\n",
    "                temp_six_peak = temp_data['Current (A)'][peak_index].nsmallest(14).index\n",
    "            if('No_24' in file_list[i]):\n",
    "                temp_six_peak = temp_data['Current (A)'][peak_index].nsmallest(24).index\n",
    "            if('No_26' in file_list[i]):\n",
    "                temp_six_peak = temp_data['Current (A)'][peak_index].nsmallest(26).index\n",
    "            if('No_30' in file_list[i]):\n",
    "                temp_six_peak = temp_data['Current (A)'][peak_index].nsmallest(30).index\n",
    "            if('No_48' in file_list[i]):\n",
    "                temp_six_peak = temp_data['Current (A)'][peak_index].nsmallest(48).index\n",
    "                \n",
    "        if('peak' in file_list[i]):\n",
    "            peak_index,_ = find_peaks(temp_data['Current (A)'],distance=3500)\n",
    "            temp_six_peak = temp_data['Current (A)'][peak_index].nlargest(6).index\n",
    "\n",
    "        for k in range(len(temp_six_peak)):\n",
    "            if(temp_six_peak[k]-num_samples_to_keep_before<0):\n",
    "                print('Too close to the start in', file_list[i].rsplit('/', 1)[1])\n",
    "                \n",
    "                fix = num_samples_to_keep_before - temp_six_peak[k]\n",
    "                samples_to_keep = pd.Series(temp_data['Current (A)'][0])\n",
    "                for q in range(fix-1):\n",
    "                    samples_to_keep = samples_to_keep.append(pd.Series(temp_data['Current (A)'][0]), ignore_index=True)\n",
    "                samples_to_keep = samples_to_keep.append(temp_data['Current (A)'][0:temp_six_peak[k]+num_samples_to_keep_after], ignore_index=True)\n",
    "                \n",
    "                print('fixed (start) length is', len(samples_to_keep))\n",
    "                print('================================================')\n",
    "                \n",
    "            elif(temp_six_peak[k]+num_samples_to_keep_after>len(temp_data['Current (A)'])):\n",
    "                print('Too close to the end in', file_list[i].rsplit('/', 1)[1])\n",
    "                \n",
    "                fix = temp_six_peak[k]+num_samples_to_keep_after-len(temp_data['Current (A)'])\n",
    "                samples_to_keep = temp_data['Current (A)'][temp_six_peak[k]-num_samples_to_keep_before:len(temp_data['Current (A)'])-1]\n",
    "                for q in range(fix+1):\n",
    "                    samples_to_keep = samples_to_keep.append(pd.Series(temp_data['Current (A)'][len(temp_data['Current (A)'])-1]), ignore_index=True)\n",
    "                \n",
    "                print('fixed (end) length is', len(samples_to_keep))\n",
    "                print('================================================')\n",
    "                \n",
    "            else:\n",
    "                samples_to_keep = temp_data['Current (A)'][temp_six_peak[k]-num_samples_to_keep_before:temp_six_peak[k]+num_samples_to_keep_after]\n",
    "            \n",
    "            reserved_samples[x].append(samples_to_keep)\n",
    "            reserved_time[x].append(time_to_keep)\n",
    "            \n",
    "            new_file_list[x] = file_list[i]\n",
    "            \n",
    "            # distinguish classes =============================================================================\n",
    "            if(any(temp_name in actual_name for temp_name in class1)):\n",
    "                class_all[x] = 0\n",
    "                class_match = True\n",
    "        \n",
    "            if(any(temp_name in actual_name for temp_name in class2)):\n",
    "                class_all[x] = 1\n",
    "                class_match = True\n",
    "\n",
    "            if(any(temp_name in actual_name for temp_name in class3)):\n",
    "                class_all[x] = 2\n",
    "                class_match = True\n",
    "                \n",
    "            if(any(temp_name in actual_name for temp_name in class4)):\n",
    "                class_all[x] = 3\n",
    "                class_match = True\n",
    "                \n",
    "            if(any(temp_name in actual_name for temp_name in class5)):\n",
    "                class_all[x] = 4\n",
    "                class_match = True\n",
    "                \n",
    "            if(any(temp_name in actual_name for temp_name in class6)):\n",
    "                class_all[x] = 5\n",
    "                class_match = True\n",
    "            \n",
    "            if(any(temp_name in actual_name for temp_name in class7)):\n",
    "                class_all[x] = 6\n",
    "                class_match = True\n",
    "                \n",
    "            if(any(temp_name in actual_name for temp_name in class8)):\n",
    "                class_all[x] = 7\n",
    "                class_match = True\n",
    "                \n",
    "            if(any(temp_name in actual_name for temp_name in class9)):\n",
    "                class_all[x] = 8\n",
    "                class_match = True\n",
    "                \n",
    "            if(any(temp_name in actual_name for temp_name in class10)):\n",
    "                class_all[x] = 9\n",
    "                class_match = True\n",
    "                \n",
    "            if(any(temp_name in actual_name for temp_name in class11)):\n",
    "                class_all[x] = 10\n",
    "                class_match = True\n",
    "\n",
    "                \n",
    "            if(not class_match):\n",
    "                print(\"Could not find any class matches for \",actual_name)\n",
    "                \n",
    "            x += 1    \n",
    "            \n",
    "    # deal with single=================================================================================================\n",
    "    else:\n",
    "        new_file_list[x] = file_list[i]\n",
    "        \n",
    "        # euqal signal length =============================================================================\n",
    "        indices_to_keep = temp_data['Current (A)'].idxmin()\n",
    "        \n",
    "        if(indices_to_keep-num_samples_to_keep_before<0):\n",
    "            print('Too close to the start in', file_list[i].rsplit('/', 1)[1])\n",
    "            \n",
    "            fix = num_samples_to_keep_before - indices_to_keep\n",
    "            samples_to_keep = pd.Series(temp_data['Current (A)'][0])\n",
    "            for q in range(fix-1):\n",
    "                samples_to_keep = samples_to_keep.append(pd.Series(temp_data['Current (A)'][0]), ignore_index=True)\n",
    "            samples_to_keep = samples_to_keep.append(temp_data['Current (A)'][0:indices_to_keep+num_samples_to_keep_after], ignore_index=True)\n",
    "            \n",
    "            print('fixed (start) length is', len(samples_to_keep))\n",
    "            print('================================================')\n",
    "        \n",
    "        elif(indices_to_keep+num_samples_to_keep_after>len(temp_data['Current (A)'])):\n",
    "            print('Too close to the end in', file_list[i].rsplit('/', 1)[1])\n",
    "                \n",
    "            fix = indices_to_keep+num_samples_to_keep_after-len(temp_data['Current (A)'])\n",
    "            samples_to_keep = temp_data['Current (A)'][indices_to_keep-num_samples_to_keep_before:len(temp_data['Current (A)'])-1]\n",
    "            for q in range(fix+1):\n",
    "                samples_to_keep = samples_to_keep.append(pd.Series(temp_data['Current (A)'][len(temp_data['Current (A)'])-1]), ignore_index=True)\n",
    "                \n",
    "            print('fixed (end) length is', len(samples_to_keep))\n",
    "            print('================================================')\n",
    "        \n",
    "        else:\n",
    "            samples_to_keep = temp_data['Current (A)'][indices_to_keep-num_samples_to_keep_before:indices_to_keep+num_samples_to_keep_after]\n",
    "            \n",
    "        reserved_samples[x].append(samples_to_keep)\n",
    "        reserved_time[x].append(time_to_keep)\n",
    "\n",
    "            \n",
    "        # distinguish classes =============================================================================\n",
    "        if(any(temp_name in actual_name for temp_name in class1)):\n",
    "            class_all[x] = 0\n",
    "            class_match = True\n",
    "        \n",
    "        if(any(temp_name in actual_name for temp_name in class2)):\n",
    "            class_all[x] = 1\n",
    "            class_match = True\n",
    "\n",
    "        if(any(temp_name in actual_name for temp_name in class3)):\n",
    "            class_all[x] = 2\n",
    "            class_match = True\n",
    "            \n",
    "        if(any(temp_name in actual_name for temp_name in class4)):\n",
    "            class_all[x] = 3\n",
    "            class_match = True\n",
    "            \n",
    "        if(any(temp_name in actual_name for temp_name in class5)):\n",
    "            class_all[x] = 4\n",
    "            class_match = True\n",
    "            \n",
    "        if(any(temp_name in actual_name for temp_name in class6)):\n",
    "            class_all[x] = 5\n",
    "            class_match = True\n",
    "            \n",
    "        if(any(temp_name in actual_name for temp_name in class7)):\n",
    "            class_all[x] = 6\n",
    "            class_match = True\n",
    "                \n",
    "        if(any(temp_name in actual_name for temp_name in class8)):\n",
    "            class_all[x] = 7\n",
    "            class_match = True\n",
    "                \n",
    "        if(any(temp_name in actual_name for temp_name in class9)):\n",
    "            class_all[x] = 8\n",
    "            class_match = True\n",
    "                \n",
    "        if(any(temp_name in actual_name for temp_name in class10)):\n",
    "            class_all[x] = 9\n",
    "            class_match = True\n",
    "                \n",
    "        if(any(temp_name in actual_name for temp_name in class11)):\n",
    "            class_all[x] = 10\n",
    "            class_match = True\n",
    "            \n",
    "        if(not class_match):\n",
    "            print(\"Could not find any class matches for \",actual_name)\n",
    "            \n",
    "        x += 1\n",
    "        # =================================================================================================      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(debug):\n",
    "    for i in range(len(reserved_samples)):\n",
    "        for j in range(len(reserved_samples[i])):\n",
    "            if(len(reserved_samples[i][j]) == total_num_samples_to_keep):\n",
    "                plt.plot(reserved_time[i][j], reserved_samples[i][j])\n",
    "                plt.xlabel(\"Time (s)\")\n",
    "                plt.ylabel(\"Current (A)\")\n",
    "                plt.title(new_file_list[i].rsplit('/', 1)[1].rsplit('\\\\',2)[2])\n",
    "                plt.pause(0.000001)\n",
    "            else:\n",
    "                print('Not enough points in', new_file_list[i].rsplit('/', 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "# ==================================================================================\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut/nyq\n",
    "    high = highcut/nyq\n",
    "    b, a = signal.butter(order, [low,high], btype='bandpass', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overall_array = np.array([])\n",
    "temp_array = []\n",
    "\n",
    "for i in range(len(reserved_samples)):\n",
    "    for j in range(len(reserved_samples[i])):\n",
    "        if(remove_dc):\n",
    "            filtered_wave = butter_bandpass_filter(reserved_samples[i][j], 1, 300, sampling_rate, 2)\n",
    "            # filtered_wave = butter_highpass_filter(reserved_samples[i][j], 0.01, sampling_rate, 2)\n",
    "            if(debug):\n",
    "                plt.plot(reserved_time[i][j],filtered_wave)\n",
    "                plt.title(new_file_list[i].rsplit('/', 1)[1].rsplit('\\\\',2)[2])\n",
    "                plt.xlabel(\"Time (s)\")\n",
    "                plt.ylabel(\"filtered_wave\")\n",
    "                plt.pause(0.000001)\n",
    "            if(use_freq_resp):\n",
    "                temp_data = np.fft.fft(filtered_wave).real\n",
    "                temp_array = np.expand_dims(np.concatenate([reserved_samples[i][j], temp_data, np.array([class_all[i]])]),0)\n",
    "                if(debug):\n",
    "                    plt.plot(reserved_time[i][j], temp_data)\n",
    "                    plt.ylim((-0.0005, 0.0005))\n",
    "                    plt.ylabel(\"FFT\")\n",
    "                    plt.title(new_file_list[i].rsplit('/', 1)[1].rsplit('\\\\',2)[2])\n",
    "                    plt.pause(0.000001)\n",
    "        \n",
    "            else:\n",
    "                temp_array = np.expand_dims(np.concatenate([filtered_wave, np.array([class_all[i]])]),0)\n",
    "                if(debug):\n",
    "                    plt.plot(reserved_time[i][j], filtered_wave)\n",
    "                    plt.ylim((-0.00025, 0.00025))\n",
    "                    plt.ylabel(\"current\")\n",
    "                    plt.xlabel(\"time\")\n",
    "                    plt.title(new_file_list[i].rsplit('/', 1)[1].rsplit('\\\\',2)[2])\n",
    "                    plt.pause(0.000001)\n",
    "        else:\n",
    "            temp_array = np.expand_dims(np.concatenate([reserved_samples[i][j], np.array([class_all[i]])]),0)\n",
    "            if(debug):\n",
    "                plt.plot(reserved_time[i][j], reserved_samples[i][j])\n",
    "                plt.ylabel(\"current\")\n",
    "                plt.xlabel(\"time\")\n",
    "                plt.title(new_file_list[i].rsplit('/', 1)[1].rsplit('\\\\',2)[2])\n",
    "                plt.pause(0.000001)\n",
    "                \n",
    "    if(len(overall_array) == 0):\n",
    "        overall_array = temp_array      \n",
    "    else:\n",
    "        overall_array = np.concatenate([overall_array, temp_array], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1094, 6001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: D://Xin Zhang/Sensor/conbination/processed_data/All_data_twoinputs.npy\n"
     ]
    }
   ],
   "source": [
    "dir_to_save = 'D://Xin Zhang/Sensor/conbination/processed_data/'\n",
    "file_name_to_save = \"All_data_twoinputs\"\n",
    "\n",
    "# if(not remove_dc):\n",
    "#     file_name_to_save = file_name_to_save + \"_original\"\n",
    "# elif(use_freq_resp):\n",
    "#     file_name_to_save = file_name_to_save + \"_freq_resp\"\n",
    "\n",
    "    \n",
    "with open(dir_to_save + file_name_to_save + '.npy', 'wb') as f:\n",
    "    np.save(f, overall_array)\n",
    "print(\"Saved to:\", dir_to_save +  file_name_to_save + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
